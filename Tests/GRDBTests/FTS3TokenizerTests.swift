import XCTest
import GRDB

class FTS3TokenizerTests: GRDBTestCase {
    
    private func match(_ db: Database, _ content: String, _ query: String) -> Bool {
        try! db.execute(sql: "INSERT INTO documents VALUES (?)", arguments: [content])
        defer {
            try! db.execute(sql: "DELETE FROM documents")
        }
        return try! Int.fetchOne(db, sql: "SELECT COUNT(*) FROM documents WHERE documents MATCH ?", arguments: [query])! > 0
    }
    
    func testSimpleTokenizer() throws {
        let dbQueue = try makeDatabaseQueue()
        try dbQueue.inDatabase { db in
            try db.create(virtualTable: "documents", using: FTS3()) { t in
                t.tokenizer = .simple
            }
            
            // simple match
            XCTAssertTrue(match(db, "abcDÃ‰F", "abcDÃ‰F"))
            
            // English stemming
            XCTAssertFalse(match(db, "database", "databases"))
            
            // diacritics in latin characters
            XCTAssertFalse(match(db, "eÃ©Ã‰", "ÃˆÃ¨e"))
            
            // unicode case
            XCTAssertFalse(match(db, "jÃ©rÃ´me", "JÃ‰RÃ”ME"))
        }
    }

    func testPorterTokenizer() throws {
        let dbQueue = try makeDatabaseQueue()
        try dbQueue.inDatabase { db in
            try db.create(virtualTable: "documents", using: FTS3()) { t in
                t.tokenizer = .porter
            }
            
            // simple match
            XCTAssertTrue(match(db, "abcDÃ‰F", "abcDÃ‰F"))
            
            // English stemming
            XCTAssertTrue(match(db, "database", "databases"))
            
            // diacritics in latin characters
            XCTAssertFalse(match(db, "eÃ©Ã‰", "ÃˆÃ¨e"))
            
            // unicode case
            XCTAssertFalse(match(db, "jÃ©rÃ´me", "JÃ‰RÃ”ME"))
        }
    }

    func testUnicode61Tokenizer() throws {
        let dbQueue = try makeDatabaseQueue()
        try dbQueue.inDatabase { db in
            try db.create(virtualTable: "documents", using: FTS3()) { t in
                t.tokenizer = .unicode61()
            }
            
            // simple match
            XCTAssertTrue(match(db, "abcDÃ‰F", "abcDÃ‰F"))
            
            // English stemming
            XCTAssertFalse(match(db, "database", "databases"))
            
            // diacritics in latin characters
            XCTAssertTrue(match(db, "eÃ©Ã‰", "ÃˆÃ¨e"))
            
            // unicode case
            XCTAssertTrue(match(db, "jÃ©rÃ´me", "JÃ‰RÃ”ME"))
        }
    }

    func testUnicode61TokenizerDiacriticsKeep() throws {
        let dbQueue = try makeDatabaseQueue()
        try dbQueue.inDatabase { db in
            try db.create(virtualTable: "documents", using: FTS3()) { t in
                t.tokenizer = .unicode61(diacritics: .keep)
            }
            
            // simple match
            XCTAssertTrue(match(db, "abcDÃ‰F", "abcDÃ‰F"))
            
            // English stemming
            XCTAssertFalse(match(db, "database", "databases"))
            
            // diacritics in latin characters
            XCTAssertFalse(match(db, "eÃ©Ã‰", "ÃˆÃ¨e"))
            
            // unicode case
            XCTAssertTrue(match(db, "jÃ©rÃ´me", "JÃ‰RÃ”ME"))
        }
    }
    
    #if GRDBCUSTOMSQLITE
    func testUnicode61TokenizerDiacriticsRemove() throws {
        let dbQueue = try makeDatabaseQueue()
        try dbQueue.inDatabase { db in
            try db.create(virtualTable: "documents", using: FTS3()) { t in
                t.tokenizer = .unicode61(diacritics: .remove)
            }
            
            // simple match
            XCTAssertTrue(match(db, "abcDÃ‰F", "abcDÃ‰F"))
            
            // English stemming
            XCTAssertFalse(match(db, "database", "databases"))
            
            // diacritics in latin characters
            XCTAssertTrue(match(db, "eÃ©Ã‰", "ÃˆÃ¨e"))
            
            // unicode case
            XCTAssertTrue(match(db, "jÃ©rÃ´me", "JÃ‰RÃ”ME"))
        }
    }
    #endif

    func testUnicode61TokenizerSeparators() throws {
        let dbQueue = try makeDatabaseQueue()
        try dbQueue.inDatabase { db in
            try db.create(virtualTable: "documents", using: FTS3()) { t in
                t.tokenizer = .unicode61(separators: ["X"])
            }
            
            XCTAssertTrue(match(db, "abcXdef", "abcXdef"))
            XCTAssertTrue(match(db, "abcXdef", "defXabc"))
            XCTAssertTrue(match(db, "abcXdef", "abc"))
            XCTAssertTrue(match(db, "abcXdef", "def"))
        }
    }

    func testUnicode61TokenizerTokenCharacters() throws {
        let dbQueue = try makeDatabaseQueue()
        try dbQueue.inDatabase { db in
            try db.create(virtualTable: "documents", using: FTS3()) { t in
                t.tokenizer = .unicode61(tokenCharacters: Set(".-"))
            }
            
            XCTAssertTrue(match(db, "2016-10-04.txt", "2016-10-04.txt"))
            XCTAssertFalse(match(db, "2016-10-04.txt", "2016"))
            XCTAssertFalse(match(db, "2016-10-04.txt", "txt"))
        }
    }
    
    func testTokenize() {
        // Empty query
        XCTAssertEqual(FTS3.tokenize(""), [])
        XCTAssertEqual(FTS3.tokenize("", withTokenizer: .simple), [])
        XCTAssertEqual(FTS3.tokenize("", withTokenizer: .porter), [])
        XCTAssertEqual(FTS3.tokenize("", withTokenizer: .unicode61()), [])
        XCTAssertEqual(FTS3.tokenize("", withTokenizer: .unicode61(diacritics: .keep)), [])
        
        XCTAssertEqual(FTS3.tokenize("?!"), [])
        XCTAssertEqual(FTS3.tokenize("?!", withTokenizer: .simple), [])
        XCTAssertEqual(FTS3.tokenize("?!", withTokenizer: .porter), [])
        XCTAssertEqual(FTS3.tokenize("?!", withTokenizer: .unicode61()), [])
        XCTAssertEqual(FTS3.tokenize("?!", withTokenizer: .unicode61(diacritics: .keep)), [])
        
        // Token queries
        XCTAssertEqual(FTS3.tokenize("Moby"), ["moby"])
        XCTAssertEqual(FTS3.tokenize("Moby", withTokenizer: .simple), ["moby"])
        XCTAssertEqual(FTS3.tokenize("Moby", withTokenizer: .porter), ["mobi"])
        XCTAssertEqual(FTS3.tokenize("Moby", withTokenizer: .unicode61()), ["moby"])
        XCTAssertEqual(FTS3.tokenize("Moby", withTokenizer: .unicode61(diacritics: .keep)), ["moby"])
        
        XCTAssertEqual(FTS3.tokenize("Ã©carlates"), ["Ã©carlates"])
        XCTAssertEqual(FTS3.tokenize("Ã©carlates", withTokenizer: .simple), ["Ã©carlates"])
        XCTAssertEqual(FTS3.tokenize("Ã©carlates", withTokenizer: .porter), ["Ã©carlates"])
        XCTAssertEqual(FTS3.tokenize("Ã©carlates", withTokenizer: .unicode61()), ["ecarlates"])
        XCTAssertEqual(FTS3.tokenize("Ã©carlates", withTokenizer: .unicode61(diacritics: .keep)), ["Ã©carlates"])
        
        XCTAssertEqual(FTS3.tokenize("fooÃ©Ä±ğŸ‘¨ğŸ‘¨ğŸ¿ğŸ‡«ğŸ‡·ğŸ‡¨ğŸ‡®"), ["fooÃ©Ä±ğŸ‘¨ğŸ‘¨ğŸ¿ğŸ‡«ğŸ‡·ğŸ‡¨ğŸ‡®"])
        XCTAssertEqual(FTS3.tokenize("fooÃ©Ä±ğŸ‘¨ğŸ‘¨ğŸ¿ğŸ‡«ğŸ‡·ğŸ‡¨ğŸ‡®", withTokenizer: .simple), ["fooÃ©Ä±ğŸ‘¨ğŸ‘¨ğŸ¿ğŸ‡«ğŸ‡·ğŸ‡¨ğŸ‡®"])
        XCTAssertEqual(FTS3.tokenize("fooÃ©Ä±ğŸ‘¨ğŸ‘¨ğŸ¿ğŸ‡«ğŸ‡·ğŸ‡¨ğŸ‡®", withTokenizer: .porter), ["fooÃ©Ä±ğŸ‘‡ï¿½ğŸ‡¨ğŸ‡®"]) // Â¯\_(ãƒ„)_/Â¯
        XCTAssertEqual(FTS3.tokenize("fooÃ©Ä±ğŸ‘¨ğŸ‘¨ğŸ¿ğŸ‡«ğŸ‡·ğŸ‡¨ğŸ‡®", withTokenizer: .unicode61()), ["fooeÄ±", "ğŸ¿"]) // Â¯\_(ãƒ„)_/Â¯
        XCTAssertEqual(FTS3.tokenize("fooÃ©Ä±ğŸ‘¨ğŸ‘¨ğŸ¿ğŸ‡«ğŸ‡·ğŸ‡¨ğŸ‡®", withTokenizer: .unicode61(diacritics: .keep)), ["fooÃ©Ä±", "ğŸ¿"]) // Â¯\_(ãƒ„)_/Â¯
        
        XCTAssertEqual(FTS3.tokenize("SQLite database"), ["sqlite", "database"])
        XCTAssertEqual(FTS3.tokenize("SQLite database", withTokenizer: .simple), ["sqlite", "database"])
        XCTAssertEqual(FTS3.tokenize("SQLite database", withTokenizer: .porter), ["sqlite", "databas"])
        XCTAssertEqual(FTS3.tokenize("SQLite database", withTokenizer: .unicode61()), ["sqlite", "database"])
        XCTAssertEqual(FTS3.tokenize("SQLite database", withTokenizer: .unicode61(diacritics: .keep)), ["sqlite", "database"])
        
        XCTAssertEqual(FTS3.tokenize("Ã‰douard Manet"), ["Ã‰douard", "manet"])
        XCTAssertEqual(FTS3.tokenize("Ã‰douard Manet", withTokenizer: .simple), ["Ã‰douard", "manet"])
        XCTAssertEqual(FTS3.tokenize("Ã‰douard Manet", withTokenizer: .porter), ["Ã‰douard", "manet"])
        XCTAssertEqual(FTS3.tokenize("Ã‰douard Manet", withTokenizer: .unicode61()), ["edouard", "manet"])
        XCTAssertEqual(FTS3.tokenize("Ã‰douard Manet", withTokenizer: .unicode61(diacritics: .keep)), ["Ã©douard", "manet"])
        
        // Prefix queries
        XCTAssertEqual(FTS3.tokenize("*"), [])
        XCTAssertEqual(FTS3.tokenize("*", withTokenizer: .simple), [])
        XCTAssertEqual(FTS3.tokenize("*", withTokenizer: .porter), [])
        XCTAssertEqual(FTS3.tokenize("*", withTokenizer: .unicode61()), [])
        XCTAssertEqual(FTS3.tokenize("*", withTokenizer: .unicode61(diacritics: .keep)), [])
        
        XCTAssertEqual(FTS3.tokenize("Robin*"), ["robin"])
        XCTAssertEqual(FTS3.tokenize("Robin*", withTokenizer: .simple), ["robin"])
        XCTAssertEqual(FTS3.tokenize("Robin*", withTokenizer: .porter), ["robin"])
        XCTAssertEqual(FTS3.tokenize("Robin*", withTokenizer: .unicode61()), ["robin"])
        XCTAssertEqual(FTS3.tokenize("Robin*", withTokenizer: .unicode61(diacritics: .keep)), ["robin"])
        
        // Phrase queries
        XCTAssertEqual(FTS3.tokenize("\"foulent muscles\""), ["foulent", "muscles"])
        XCTAssertEqual(FTS3.tokenize("\"foulent muscles\"", withTokenizer: .simple), ["foulent", "muscles"])
        XCTAssertEqual(FTS3.tokenize("\"foulent muscles\"", withTokenizer: .porter), ["foulent", "muscl"])
        XCTAssertEqual(FTS3.tokenize("\"foulent muscles\"", withTokenizer: .unicode61()), ["foulent", "muscles"])
        XCTAssertEqual(FTS3.tokenize("\"foulent muscles\"", withTokenizer: .unicode61(diacritics: .keep)), ["foulent", "muscles"])
        
        XCTAssertEqual(FTS3.tokenize("\"Kim Stan* Robin*\""), ["kim", "stan", "robin"])
        XCTAssertEqual(FTS3.tokenize("\"Kim Stan* Robin*\"", withTokenizer: .simple), ["kim", "stan", "robin"])
        XCTAssertEqual(FTS3.tokenize("\"Kim Stan* Robin*\"", withTokenizer: .porter), ["kim", "stan", "robin"])
        XCTAssertEqual(FTS3.tokenize("\"Kim Stan* Robin*\"", withTokenizer: .unicode61()), ["kim", "stan", "robin"])
        XCTAssertEqual(FTS3.tokenize("\"Kim Stan* Robin*\"", withTokenizer: .unicode61(diacritics: .keep)), ["kim", "stan", "robin"])
        
        // Logical queries
        XCTAssertEqual(FTS3.tokenize("years AND months"), ["years", "and", "months"])
        XCTAssertEqual(FTS3.tokenize("years AND months", withTokenizer: .simple), ["years", "and", "months"])
        XCTAssertEqual(FTS3.tokenize("years AND months", withTokenizer: .porter), ["year", "and", "month"])
        XCTAssertEqual(FTS3.tokenize("years AND months", withTokenizer: .unicode61()), ["years", "and", "months"])
        XCTAssertEqual(FTS3.tokenize("years AND months", withTokenizer: .unicode61(diacritics: .keep)), ["years", "and", "months"])
        
        // column queries
        XCTAssertEqual(FTS3.tokenize("title:brest"), ["title", "brest"])
        XCTAssertEqual(FTS3.tokenize("title:brest", withTokenizer: .simple), ["title", "brest"])
        XCTAssertEqual(FTS3.tokenize("title:brest", withTokenizer: .porter), ["titl", "brest"])
        XCTAssertEqual(FTS3.tokenize("title:brest", withTokenizer: .unicode61()), ["title", "brest"])
        XCTAssertEqual(FTS3.tokenize("title:brest", withTokenizer: .unicode61(diacritics: .keep)), ["title", "brest"])
    }
}
